{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 1.7492 - accuracy: 0.3834 - val_loss: 1.4263 - val_accuracy: 0.5070\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 63s 2ms/step - loss: 1.3793 - accuracy: 0.5135 - val_loss: 1.3013 - val_accuracy: 0.5441\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 59s 1ms/step - loss: 1.2488 - accuracy: 0.5597 - val_loss: 1.2038 - val_accuracy: 0.5732\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 1.1624 - accuracy: 0.5909 - val_loss: 1.2206 - val_accuracy: 0.5801\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 1.0861 - accuracy: 0.6206 - val_loss: 1.1436 - val_accuracy: 0.6013\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 1.0266 - accuracy: 0.6410 - val_loss: 1.1145 - val_accuracy: 0.6090\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.9722 - accuracy: 0.6584 - val_loss: 1.2043 - val_accuracy: 0.5930\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 63s 2ms/step - loss: 0.9312 - accuracy: 0.6740 - val_loss: 1.0620 - val_accuracy: 0.6373\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.8878 - accuracy: 0.6894 - val_loss: 0.9922 - val_accuracy: 0.6632\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.8466 - accuracy: 0.7029 - val_loss: 1.0172 - val_accuracy: 0.6588\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.8162 - accuracy: 0.7161 - val_loss: 1.0855 - val_accuracy: 0.6475\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.7823 - accuracy: 0.7286 - val_loss: 1.0295 - val_accuracy: 0.6659\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 0.7550 - accuracy: 0.7372 - val_loss: 1.0590 - val_accuracy: 0.6616\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.7306 - accuracy: 0.7452 - val_loss: 1.1277 - val_accuracy: 0.6476\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.7100 - accuracy: 0.7550 - val_loss: 0.9946 - val_accuracy: 0.6776\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.6831 - accuracy: 0.7631 - val_loss: 1.0034 - val_accuracy: 0.6827\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.6604 - accuracy: 0.7715 - val_loss: 1.0043 - val_accuracy: 0.6780\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 78s 2ms/step - loss: 0.6364 - accuracy: 0.7805 - val_loss: 1.0706 - val_accuracy: 0.6617\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 0.6208 - accuracy: 0.7854 - val_loss: 1.0672 - val_accuracy: 0.6768\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.6014 - accuracy: 0.7914 - val_loss: 1.0044 - val_accuracy: 0.6823\n",
      "10000/10000 [==============================] - 6s 591us/step\n",
      "Test score: 1.0181963134765626\n",
      "Test accuracy: 0.6729999780654907\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "ssl._create_default_https_context=ssl._create_unverified_context\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 1.8047 - accuracy: 0.3477 - val_loss: 1.3973 - val_accuracy: 0.4981\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 101s 3ms/step - loss: 1.3012 - accuracy: 0.5388 - val_loss: 1.2543 - val_accuracy: 0.5452\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 98s 2ms/step - loss: 1.0952 - accuracy: 0.6147 - val_loss: 1.0473 - val_accuracy: 0.6265\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.9686 - accuracy: 0.6606 - val_loss: 0.8890 - val_accuracy: 0.6901\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 103s 3ms/step - loss: 0.8817 - accuracy: 0.6929 - val_loss: 0.8110 - val_accuracy: 0.7177\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.8151 - accuracy: 0.7151 - val_loss: 0.8581 - val_accuracy: 0.7043\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.7609 - accuracy: 0.7370 - val_loss: 0.8800 - val_accuracy: 0.6955\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 101s 3ms/step - loss: 0.7146 - accuracy: 0.7508 - val_loss: 0.7855 - val_accuracy: 0.7305\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.6762 - accuracy: 0.7643 - val_loss: 0.6935 - val_accuracy: 0.7631\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.6397 - accuracy: 0.7789 - val_loss: 0.7444 - val_accuracy: 0.7479\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 101s 3ms/step - loss: 0.6162 - accuracy: 0.7872 - val_loss: 0.7706 - val_accuracy: 0.7442\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 97s 2ms/step - loss: 0.5955 - accuracy: 0.7946 - val_loss: 0.6844 - val_accuracy: 0.7732\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.5730 - accuracy: 0.8023 - val_loss: 0.7014 - val_accuracy: 0.7708\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 103s 3ms/step - loss: 0.5667 - accuracy: 0.8061 - val_loss: 0.7802 - val_accuracy: 0.7503\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 97s 2ms/step - loss: 0.5505 - accuracy: 0.8138 - val_loss: 0.7138 - val_accuracy: 0.7625\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 97s 2ms/step - loss: 0.5425 - accuracy: 0.8164 - val_loss: 0.8879 - val_accuracy: 0.7212\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 103s 3ms/step - loss: 0.5438 - accuracy: 0.8178 - val_loss: 0.8996 - val_accuracy: 0.7356\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 97s 2ms/step - loss: 0.5331 - accuracy: 0.8210 - val_loss: 0.7578 - val_accuracy: 0.7729\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.5402 - accuracy: 0.8203 - val_loss: 0.7122 - val_accuracy: 0.7647\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 101s 3ms/step - loss: 0.5377 - accuracy: 0.8219 - val_loss: 0.7518 - val_accuracy: 0.7838\n",
      "10000/10000 [==============================] - 9s 950us/step\n",
      "Test score: 0.7801079533576966\n",
      "Test accuracy: 0.7807999849319458\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training set images...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preview\\\\cifar_0_2780.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ceef8bab58c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (1, 3, 32, 32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m for x_aug in datagen.flow(x, batch_size=1,\n\u001b[1;32m---> 43\u001b[1;33m save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_aug\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mNUM_TO_AUGMENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[0mhash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     format=self.save_format)\n\u001b[1;32m--> 165\u001b[1;33m                 \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[0mbatch_x_miscs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_misc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         output = (batch_x if batch_x_miscs == []\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2079\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2080\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2081\u001b[1;33m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preview\\\\cifar_0_2780.jpeg'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ssl\n",
    "import os\n",
    "ssl._create_default_https_context=ssl._create_unverified_context\n",
    "save_to_dir = os.getcwd()\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "NUM_TO_AUGMENT=5\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# augumenting\n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i] # (3, 32, 32)\n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "for x_aug in datagen.flow(x, batch_size=1,\n",
    "save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "    if num_aug >= NUM_TO_AUGMENT:\n",
    "        break\n",
    "    xtas.append(x_aug[0])\n",
    "    num_aug += 1\n",
    "#fit the dataget\n",
    "datagen.fit(X_train)\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# train\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE), samples_per_epoch=X_train.shape[0],\n",
    "epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this Assignment I worked with CIFAR-10. Withing the first block you can see the original code was able to test at:\n",
    "Test score: 1.0181963134765626\n",
    "Test accuracy: 0.6729999780654907\n",
    "\n",
    "Once I added the code to create a deeper net work the program was able to test at:\n",
    "Test score: 0.7801079533576966\n",
    "Test accuracy: 0.7807999849319458\n",
    "\n",
    "This proved that the deeper network was able to suitable for the preformance I was looking for. While coding the augmentation I ran into an issue with the directory named \"preview\". I was unable to find a fix for this error but the augmentation code is still provided. \n",
    "\n",
    "When it comes to ethical concerns in facial reconition, my biggest worry would be the fact that your face has to be stored somewhere. Though its not something you see happening it day to day life, imagine if there is someone you don't want to find you who could hack into a database that is holding that image. If they could trace where the facial image is being used that could potentially put someone's life in danger.\n",
    "\n",
    "Heilweil, R. (2020, February 18). Why algorithms can be racist and sexist. Vox. https://www.vox.com/recode/2020/2/18/21121286/algorithms-bias-discrimination-facial-recognition-transparency\n",
    "\n",
    "Janet. (2021, May 14). Overcome and prevent bias in AI. Figure Eight Federal. https://f8federal.com/overcome-and-prevent-ai-bias/\n",
    "\n",
    "Rosaria Silipo, By, & Silipo, R. (2020, March 5). Rosaria Silipo. CustomerThink. https://customerthink.com/how-to-keep-bias-out-of-your-ai-models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
